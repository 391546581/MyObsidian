#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›…æ€è¯æ±‡è‡ªåŠ¨æå–ä¸åˆ†çº§å·¥å…·
ä»å­—å¹•æ–‡ä»¶(SRT/VTT)ä¸­æå–è¯æ±‡,è‡ªåŠ¨åˆ†çº§ä¸ºBrand5/7/9
"""

import re
import os
from collections import Counter
from pathlib import Path
import csv
import json

class SubtitleVocabularyExtractor:
    """å­—å¹•è¯æ±‡æå–å™¨"""
    
    def __init__(self):
        # åŠ è½½è¯æ±‡åˆ†çº§æ•°æ®åº“
        self.brand5_words = self._load_brand5_words()
        self.brand7_words = self._load_brand7_words()
        self.brand9_words = self._load_brand9_words()
        
        # åœç”¨è¯(ä¸éœ€è¦å­¦ä¹ çš„å¸¸è§è¯)
        self.stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',
            'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
            'would', 'should', 'could', 'may', 'might', 'must', 'can', 'this',
            'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they'
        }
    
    def _load_brand5_words(self):
        """åŠ è½½Brand5è¯æ±‡åº“(åŸºç¡€é«˜é¢‘è¯)"""
        # è¿™é‡Œæ˜¯ç¤ºä¾‹æ•°æ®,å®é™…ä½¿ç”¨æ—¶åº”è¯¥ä»æ–‡ä»¶åŠ è½½
        return {
            'make', 'get', 'go', 'do', 'say', 'see', 'know', 'think', 'take',
            'come', 'want', 'use', 'find', 'give', 'tell', 'work', 'call',
            'try', 'ask', 'need', 'feel', 'become', 'leave', 'put', 'mean',
            'keep', 'let', 'begin', 'seem', 'help', 'talk', 'turn', 'start',
            'show', 'hear', 'play', 'run', 'move', 'like', 'live', 'believe',
            'hold', 'bring', 'happen', 'write', 'provide', 'sit', 'stand',
            'lose', 'pay', 'meet', 'include', 'continue', 'set', 'learn',
            'change', 'lead', 'understand', 'watch', 'follow', 'stop', 'create',
            'speak', 'read', 'allow', 'add', 'spend', 'grow', 'open', 'walk',
            'win', 'offer', 'remember', 'love', 'consider', 'appear', 'buy',
            'wait', 'serve', 'die', 'send', 'expect', 'build', 'stay', 'fall',
            'cut', 'reach', 'kill', 'remain', 'suggest', 'raise', 'pass',
            'important', 'good', 'new', 'first', 'last', 'long', 'great', 'little',
            'own', 'other', 'old', 'right', 'big', 'high', 'different', 'small',
            'large', 'next', 'early', 'young', 'few', 'public', 'bad', 'same',
            'able', 'problem', 'increase', 'number', 'people', 'time', 'year',
            'way', 'day', 'thing', 'man', 'world', 'life', 'hand', 'part',
            'child', 'eye', 'woman', 'place', 'work', 'week', 'case', 'point',
            'government', 'company'
        }
    
    def _load_brand7_words(self):
        """åŠ è½½Brand7è¯æ±‡åº“(é›…æ€é«˜åˆ†è¯)"""
        return {
            'acquire', 'constitute', 'crucial', 'demonstrate', 'enhance',
            'facilitate', 'implement', 'indicate', 'maintain', 'obtain',
            'participate', 'perceive', 'pursue', 'require', 'retain',
            'significant', 'subsequent', 'sufficient', 'utilize', 'assess',
            'attribute', 'capacity', 'component', 'comprehensive', 'conduct',
            'consequence', 'considerable', 'consist', 'constant', 'construct',
            'consume', 'context', 'contribute', 'convert', 'cooperate',
            'coordinate', 'core', 'corporate', 'correspond', 'create',
            'criteria', 'crucial', 'culture', 'data', 'debate', 'decade',
            'decline', 'define', 'demonstrate', 'denote', 'derive', 'design',
            'despite', 'detect', 'device', 'devote', 'dimension', 'diminish',
            'discrete', 'discriminate', 'displace', 'display', 'dispose',
            'distinct', 'distribute', 'diverse', 'document', 'domain',
            'domestic', 'dominate', 'draft', 'drama', 'duration', 'dynamic',
            'economy', 'edit', 'element', 'eliminate', 'emerge', 'emphasis',
            'empirical', 'enable', 'encounter', 'energy', 'enforce', 'enhance',
            'enormous', 'ensure', 'entity', 'environment', 'equate', 'equip',
            'equivalent', 'erode', 'error', 'establish', 'estate', 'estimate',
            'ethic', 'ethnic', 'evaluate', 'eventual', 'evident', 'evolve',
            'exceed', 'exclude', 'exhibit', 'expand', 'expert', 'explicit',
            'exploit', 'export', 'expose', 'external', 'extract', 'facilitate',
            'factor', 'feature', 'federal', 'fee', 'file', 'final', 'finance',
            'finite', 'flexible', 'fluctuate', 'focus', 'format', 'formula',
            'forthcoming', 'foundation', 'founded', 'framework', 'function',
            'fund', 'fundamental', 'furthermore', 'gender', 'generate',
            'generation', 'globe', 'goal', 'grade', 'grant', 'guarantee',
            'guideline', 'hence', 'hierarchy', 'highlight', 'hypothesis',
            'identical', 'identify', 'ideology', 'ignorance', 'illustrate',
            'image', 'immigrate', 'impact', 'implement', 'implicate', 'implicit',
            'imply', 'impose', 'incentive', 'incidence', 'incline', 'income',
            'incorporate', 'index', 'indicate', 'individual', 'induce',
            'inevitable', 'infer', 'infrastructure', 'inherent', 'inhibit',
            'initial', 'initiate', 'injure', 'innovate', 'input', 'insert',
            'insight', 'inspect', 'instance', 'institute', 'instruct',
            'integral', 'integrate', 'integrity', 'intelligence', 'intense',
            'interact', 'intermediate', 'internal', 'interpret', 'interval',
            'intervene', 'intrinsic', 'invest', 'investigate', 'invoke',
            'involve', 'isolate', 'issue', 'item', 'job', 'journal', 'justify',
            'label', 'labor', 'layer', 'lecture', 'legal', 'legislate',
            'levy', 'liberal', 'license', 'likewise', 'link', 'locate', 'logic'
        }
    
    def _load_brand9_words(self):
        """åŠ è½½Brand9è¯æ±‡åº“(å­¦æœ¯é«˜é˜¶è¯)"""
        return {
            'ascertain', 'corroborate', 'ubiquitous', 'mitigate', 'elucidate',
            'substantiate', 'ameliorate', 'exacerbate', 'proliferate', 'disseminate',
            'promulgate', 'inculcate', 'edify', 'pedagogical', 'erudite',
            'didactic', 'matriculate', 'autodidact', 'juxtapose', 'paradigm',
            'quintessential', 'salient', 'tangential', 'vicarious', 'zealous',
            'aberration', 'abstruse', 'acumen', 'adroit', 'aesthetic',
            'alleviate', 'ambiguous', 'ameliorate', 'anachronistic', 'analogous',
            'anomaly', 'antithesis', 'apathy', 'arbitrary', 'archaic',
            'arduous', 'articulate', 'assiduous', 'astute', 'audacious',
            'auspicious', 'austere', 'autonomous', 'avarice', 'banal',
            'benevolent', 'bolster', 'burgeon', 'cacophony', 'candid',
            'capricious', 'catalyst', 'caustic', 'censure', 'charlatan',
            'circumspect', 'clandestine', 'coalesce', 'cogent', 'commensurate',
            'compelling', 'complacent', 'complement', 'complicit', 'comprehensive',
            'conciliatory', 'concise', 'concomitant', 'condone', 'confound',
            'congenial', 'conjecture', 'connote', 'conscientious', 'consensus',
            'construe', 'contentious', 'contextualize', 'contrite', 'convoluted',
            'copious', 'corroborate', 'credulous', 'cryptic', 'culpable',
            'cursory', 'curtail', 'cynical', 'debacle', 'debilitate',
            'decorous', 'decry', 'deference', 'delineate', 'deleterious',
            'demagogue', 'demarcate', 'demeanor', 'demur', 'denigrate',
            'denote', 'depict', 'deprecate', 'deride', 'derivative',
            'desiccate', 'desultory', 'deterrent', 'detrimental', 'deviate',
            'dexterous', 'diaphanous', 'diatribe', 'dichotomy', 'didactic',
            'diffident', 'digress', 'dilapidated', 'dilatory', 'diligent',
            'diminutive', 'discern', 'discomfit', 'discordant', 'discourse',
            'discrepancy', 'discrete', 'discriminate', 'disdain', 'disingenuous',
            'disparage', 'disparate', 'dispassionate', 'disseminate', 'dissent',
            'dissolution', 'dissonance', 'distend', 'divergent', 'divulge',
            'dogmatic', 'dormant', 'dubious', 'duplicity', 'ebullient',
            'eccentric', 'eclectic', 'efficacious', 'effrontery', 'egalitarian',
            'egregious', 'elaborate', 'elicit', 'eloquent', 'elucidate',
            'elusive', 'emaciated', 'embellish', 'eminent', 'empirical',
            'emulate', 'endemic', 'enervate', 'engender', 'enigmatic',
            'enmity', 'ennui', 'ephemeral', 'equanimity', 'equivocal',
            'eradicate', 'erratic', 'erstwhile', 'erudite', 'esoteric',
            'espouse', 'ethereal', 'euphemism', 'evanescent', 'exacerbate',
            'exacting', 'exalt', 'exasperate', 'exemplary', 'exhaustive',
            'exhort', 'exigent', 'exonerate', 'expedient', 'expedite',
            'explicate', 'explicit', 'exploit', 'expound', 'expunge',
            'extant', 'extemporaneous', 'extenuate', 'extol', 'extraneous',
            'extrapolate', 'extricate', 'exuberant', 'facetious', 'facilitate',
            'fallacious', 'fastidious', 'fatuous', 'fawn', 'feasible',
            'feckless', 'fecund', 'felicitous', 'fervent', 'fervid'
        }
    
    def parse_srt(self, file_path):
        """è§£æSRTå­—å¹•æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤æ—¶é—´æˆ³å’Œåºå·,åªä¿ç•™æ–‡æœ¬
        # SRTæ ¼å¼: åºå·\næ—¶é—´æˆ³\næ–‡æœ¬\nç©ºè¡Œ
        text = re.sub(r'\d+\n\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}\n', '', content)
        text = re.sub(r'^\d+$', '', text, flags=re.MULTILINE)
        
        return text
    
    def parse_vtt(self, file_path):
        """è§£æVTTå­—å¹•æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤WEBVTTå¤´å’Œæ—¶é—´æˆ³
        text = re.sub(r'WEBVTT.*?\n\n', '', content)
        text = re.sub(r'\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}.*?\n', '', content)
        
        return text
    
    def extract_words(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å•è¯"""
        # è½¬æ¢ä¸ºå°å†™
        text = text.lower()
        
        # æå–å•è¯(åªä¿ç•™å­—æ¯)
        words = re.findall(r'\b[a-z]+\b', text)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        words = [w for w in words if w not in self.stop_words and len(w) > 3]
        
        return words
    
    def classify_word(self, word):
        """åˆ†ç±»å•è¯åˆ°Brand5/7/9"""
        if word in self.brand9_words:
            return 'Brand9'
        elif word in self.brand7_words:
            return 'Brand7'
        elif word in self.brand5_words:
            return 'Brand5'
        else:
            # æœªçŸ¥è¯æ±‡,æ ¹æ®é•¿åº¦å’Œå¤æ‚åº¦ä¼°ç®—
            if len(word) <= 5:
                return 'Brand5'
            elif len(word) <= 8:
                return 'Brand7'
            else:
                return 'Brand9'
    
    def analyze_subtitle(self, file_path, min_frequency=2):
        """åˆ†æå­—å¹•æ–‡ä»¶,æå–é«˜é¢‘è¯æ±‡"""
        # è§£æå­—å¹•
        if file_path.endswith('.srt'):
            text = self.parse_srt(file_path)
        elif file_path.endswith('.vtt'):
            text = self.parse_vtt(file_path)
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼,è¯·ä½¿ç”¨.srtæˆ–.vttæ–‡ä»¶")
        
        # æå–å•è¯
        words = self.extract_words(text)
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = Counter(words)
        
        # è¿‡æ»¤ä½é¢‘è¯
        high_freq_words = {word: freq for word, freq in word_freq.items() 
                          if freq >= min_frequency}
        
        # åˆ†ç±»
        classified = {
            'Brand5': [],
            'Brand7': [],
            'Brand9': [],
            'Unknown': []
        }
        
        for word, freq in high_freq_words.items():
            brand = self.classify_word(word)
            classified[brand].append({
                'word': word,
                'frequency': freq,
                'brand': brand
            })
        
        # æŒ‰é¢‘ç‡æ’åº
        for brand in classified:
            classified[brand].sort(key=lambda x: x['frequency'], reverse=True)
        
        return classified
    
    def export_to_csv(self, classified_words, output_file):
        """å¯¼å‡ºåˆ°CSVæ–‡ä»¶(å¯å¯¼å…¥Anki)"""
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            # å†™å…¥è¡¨å¤´
            writer.writerow(['å•è¯', 'ç­‰çº§', 'é¢‘ç‡', 'è¯æ€§', 'é‡Šä¹‰', 'æ ‡ç­¾'])
            
            # å†™å…¥æ•°æ®
            for brand in ['Brand5', 'Brand7', 'Brand9']:
                for item in classified_words[brand]:
                    writer.writerow([
                        item['word'],
                        item['brand'],
                        item['frequency'],
                        '',  # è¯æ€§éœ€è¦æ‰‹åŠ¨å¡«å†™æˆ–APIæŸ¥è¯¢
                        '',  # é‡Šä¹‰éœ€è¦æ‰‹åŠ¨å¡«å†™æˆ–APIæŸ¥è¯¢
                        f"IELTS,{item['brand']},å­—å¹•æå–"
                    ])
        
        print(f"âœ… å·²å¯¼å‡ºåˆ°: {output_file}")
    
    def export_to_obsidian(self, classified_words, output_dir):
        """å¯¼å‡ºä¸ºObsidianç¬”è®°"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        for brand in ['Brand5', 'Brand7', 'Brand9']:
            brand_dir = output_path / brand
            brand_dir.mkdir(exist_ok=True)
            
            for item in classified_words[brand]:
                word = item['word']
                freq = item['frequency']
                
                # åˆ›å»ºç¬”è®°æ–‡ä»¶
                note_content = f"""---
è¯æ±‡: {word}
ç­‰çº§: {brand}
é¢‘ç‡: {freq}
æ¥æº: å­—å¹•æå–
åˆ›å»ºæ—¥æœŸ: {self._get_today()}
---

# {word}

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯
- **å‡ºç°é¢‘ç‡**: {freq}æ¬¡
- **ç­‰çº§**: {brand}
- **æ¥æº**: å­¦ä¹ è§†é¢‘å­—å¹•

## ğŸ“ åŸºæœ¬ä¿¡æ¯
**è¯æ€§**: _å¾…è¡¥å……_  
**éŸ³æ ‡**: _å¾…è¡¥å……_  
**é‡Šä¹‰**: _å¾…è¡¥å……_

## ğŸ’¡ ä¾‹å¥ (æ¥è‡ªå­—å¹•)
> _å¾…æå–å…·ä½“ä¾‹å¥_

## ğŸ”— å…³è”è¯æ±‡
_å¾…è¡¥å……_

---

#IELTS/{brand} #å­—å¹•æå– #å¾…å®Œå–„
"""
                
                note_file = brand_dir / f"{word}.md"
                with open(note_file, 'w', encoding='utf-8') as f:
                    f.write(note_content)
        
        print(f"âœ… å·²å¯¼å‡ºåˆ°Obsidian: {output_dir}")
    
    def _get_today(self):
        """è·å–ä»Šå¤©æ—¥æœŸ"""
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d')
    
    def generate_report(self, classified_words):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š å­—å¹•è¯æ±‡åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        total = sum(len(classified_words[brand]) for brand in ['Brand5', 'Brand7', 'Brand9'])
        
        print(f"\næ€»è®¡æå–é«˜é¢‘è¯æ±‡: {total} ä¸ª\n")
        
        for brand in ['Brand5', 'Brand7', 'Brand9']:
            words = classified_words[brand]
            count = len(words)
            percentage = (count / total * 100) if total > 0 else 0
            
            print(f"{brand}: {count} ä¸ª ({percentage:.1f}%)")
            
            if count > 0:
                print(f"  Top 5: {', '.join([w['word'] for w in words[:5]])}")
                print()
        
        print("="*60)
        
        # å­¦ä¹ å»ºè®®
        print("\nğŸ’¡ å­¦ä¹ å»ºè®®:")
        print(f"  - Brand5è¯æ±‡({len(classified_words['Brand5'])}ä¸ª): é‡ç‚¹è®°å¿†å›ºå®šæ­é…")
        print(f"  - Brand7è¯æ±‡({len(classified_words['Brand7'])}ä¸ª): é‡ç‚¹è®°å¿†åŒä¹‰æ›¿æ¢")
        print(f"  - Brand9è¯æ±‡({len(classified_words['Brand9'])}ä¸ª): é‡ç‚¹è®°å¿†ä½¿ç”¨è¯­å¢ƒ")
        print()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ é›…æ€è¯æ±‡è‡ªåŠ¨æå–å·¥å…·")
    print("="*60)
    
    # åˆ›å»ºæå–å™¨
    extractor = SubtitleVocabularyExtractor()
    
    # ç¤ºä¾‹ç”¨æ³•
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. å°†å­—å¹•æ–‡ä»¶(.srtæˆ–.vtt)æ”¾åœ¨æŒ‡å®šç›®å½•")
    print("2. è¿è¡Œè„šæœ¬åˆ†æ")
    print("3. å¯¼å‡ºä¸ºCSV(Anki)æˆ–Markdown(Obsidian)")
    print()
    
    # äº¤äº’å¼è¾“å…¥
    subtitle_file = input("è¯·è¾“å…¥å­—å¹•æ–‡ä»¶è·¯å¾„ (æˆ–æŒ‰Enterä½¿ç”¨ç¤ºä¾‹): ").strip()
    
    if not subtitle_file:
        print("\nâš ï¸  æœªæä¾›æ–‡ä»¶è·¯å¾„,æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹...")
        print("\nç¤ºä¾‹ä»£ç :")
        print("""
# åˆ†æå­—å¹•æ–‡ä»¶
classified = extractor.analyze_subtitle('path/to/subtitle.srt', min_frequency=2)

# ç”ŸæˆæŠ¥å‘Š
extractor.generate_report(classified)

# å¯¼å‡ºåˆ°CSV (å¯å¯¼å…¥Anki)
extractor.export_to_csv(classified, 'output/vocabulary.csv')

# å¯¼å‡ºåˆ°Obsidian
extractor.export_to_obsidian(classified, 'output/obsidian_notes')
        """)
        return
    
    if not os.path.exists(subtitle_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {subtitle_file}")
        return
    
    # åˆ†æ
    print(f"\nğŸ” æ­£åœ¨åˆ†æ: {subtitle_file}")
    classified = extractor.analyze_subtitle(subtitle_file, min_frequency=2)
    
    # ç”ŸæˆæŠ¥å‘Š
    extractor.generate_report(classified)
    
    # è¯¢é—®å¯¼å‡ºé€‰é¡¹
    print("\nå¯¼å‡ºé€‰é¡¹:")
    print("1. å¯¼å‡ºä¸ºCSV (å¯å¯¼å…¥Anki)")
    print("2. å¯¼å‡ºä¸ºObsidianç¬”è®°")
    print("3. ä¸¤è€…éƒ½å¯¼å‡º")
    
    choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice in ['1', '3']:
        csv_file = input("CSVè¾“å‡ºè·¯å¾„ (é»˜è®¤: vocabulary.csv): ").strip() or 'vocabulary.csv'
        extractor.export_to_csv(classified, csv_file)
    
    if choice in ['2', '3']:
        obs_dir = input("Obsidianè¾“å‡ºç›®å½• (é»˜è®¤: obsidian_notes): ").strip() or 'obsidian_notes'
        extractor.export_to_obsidian(classified, obs_dir)
    
    print("\nâœ… å®Œæˆ!")


if __name__ == '__main__':
    main()
